{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device in use: '5'\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from input_pipeline import train_data, eval_data\n",
    "from model_fns import resnet50, inceptionv4, vgg16, classification\n",
    "from loss_fns  import triplet_loss_train, triplet_loss_eval, classification_loss\n",
    "from loss_fns  import triplet_summary, classification_summary\n",
    "\n",
    "!echo \"GPU Device in use: '$CUDA_VISIBLE_DEVICES'\"\n",
    "\n",
    "# Feature choices\n",
    "num_samples = 100000\n",
    "num_eval    =   2200\n",
    "batch_size  =    200\n",
    "\n",
    "# Model for loading\n",
    "model_vgg16 = \\\n",
    "{\n",
    "    'name_out'         : 'vgg16',\n",
    "    'model_fn'         : vgg16,\n",
    "    'model_name'       : 'triplet_vgg16_classificaton_validation_lr0.0001_bs30_es64_normalized_exp',\n",
    "    'feed_mode'        : 'triplets',\n",
    "    'scope_to_restore' : 'triplet_model',\n",
    "}\n",
    "\n",
    "model_inception = \\\n",
    "{\n",
    "    'name_out'         : 'inception',\n",
    "    'model_fn'         : inceptionv4,\n",
    "    'model_name'       : 'triplet_inceptionv4_classificaton_validation',\n",
    "    'feed_mode'        : 'triplets',\n",
    "    'scope_to_restore' : 'triplets',\n",
    "}\n",
    "\n",
    "model_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'resnet',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'triplet_resnet_classificaton_validation2layers_lr0.0001_bs30_es64_normalized_exp',\n",
    "    'feed_mode'        : 'triplets',\n",
    "    'scope_to_restore' : 'triplet_model',\n",
    "}\n",
    "\n",
    "model_threesplit_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'threesplit_resnet',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'triplet_threesplit_resnet_classificaton_validation2layers_lr0.0001_bs30_es64_normalized_exp',\n",
    "    'feed_mode'        : 'threesplit',\n",
    "    'scope_to_restore' : 'threesplit',\n",
    "}\n",
    "\n",
    "model_direct_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'direct_resnet',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'direct_resnet',\n",
    "    'feed_mode'        : None,\n",
    "    'scope_to_restore' : 'classifier/CNN/',\n",
    "}\n",
    "\n",
    "model_step5k_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'step5k_resnet',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'triplet_resnet_classificaton_validation2layers_lr0.0001_bs30_es64_normalized_exp',\n",
    "    'feed_mode'        : 'triplets',\n",
    "    'scope_to_restore' : 'triplet_model',\n",
    "    'checkpoint'       : 5000\n",
    "}\n",
    "\n",
    "model_step5k_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'step5k_resnet',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'triplet_resnet_classificaton_validation2layers_lr0.0001_bs30_es64_normalized_exp',\n",
    "    'feed_mode'        : 'triplets',\n",
    "    'scope_to_restore' : 'triplet_model',\n",
    "    'checkpoint'       : 5000\n",
    "}\n",
    "\n",
    "model_hingeloss_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'threesplit_resnet_hingeloss',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'threesplit_resnet_hingeloss_alpha1',\n",
    "    'feed_mode'        : 'threesplit',\n",
    "    'scope_to_restore' : 'threesplit'\n",
    "}\n",
    "\n",
    "model_step20k_hingeloss_resnet = \\\n",
    "{\n",
    "    'name_out'         : 'step20k_threesplit_resnet_hingeloss',\n",
    "    'model_fn'         : resnet50,\n",
    "    'model_name'       : 'threesplit_resnet_hingeloss_alpha1',\n",
    "    'feed_mode'        : 'threesplit',\n",
    "    'scope_to_restore' : 'threesplit',\n",
    "    'checkpoint'       : 20000\n",
    "}\n",
    "\n",
    "models = [model_step20k_hingeloss_resnet]\n",
    "# models = [model_vgg16, model_inception, \n",
    "#             model_threesplit_resnet, model_resnet, \n",
    "#             model_direct_resnet, model_step5k_resnet\n",
    "#             model_hingeloss_resnet, model_step20k_hingeloss_resnet]\n",
    "\n",
    "# Folders for storage/retrival\n",
    "main_directory  = '../'\n",
    "checkpoints_directory = main_directory + 'checkpts/'\n",
    "features_directory    = main_directory + 'features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Input #\n",
    "#########\n",
    "\n",
    "_, _, images, labels           = train_data(batch_size=batch_size, epochs=1, mode=None, small=True)\n",
    "_, _, eval_images, eval_labels = eval_data (batch_size=batch_size, epochs=1, mode=None, small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplabels = np.load(features_directory + 'labels.npy')\n",
    "npimages = np.load(features_directory + 'images.npy')\n",
    "\n",
    "npvlabels = np.load(features_directory + 'eval_labels.npy')\n",
    "npvimages = np.load(features_directory + 'eval_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Write images & labels to file #\n",
    "#################################\n",
    "\n",
    "# if not os.path.exists(features_directory):\n",
    "#     os.makedirs(features_directory)\n",
    "\n",
    "# nplabels = np.empty((0),         dtype=bytes)\n",
    "# npimages = np.zeros((0,224*224), dtype=np.uint8)\n",
    "\n",
    "# npvlabels = np.empty((0),         dtype=bytes)\n",
    "# npvimages = np.zeros((0,224*224), dtype=np.uint8)\n",
    "\n",
    "# with tf.Session() as sess: \n",
    "#     init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "#     sess.run(init_op)\n",
    "      \n",
    "#     num_runs = (num_samples // batch_size) + 1\n",
    "#     for i in range(num_runs):\n",
    "#         if (i+1) % 5 == 0: print(\"Step {} from {}\".format(i+1, num_runs))\n",
    "#         num_to_take = batch_size\n",
    "#         if i+1 == num_runs: num_to_take = num_samples - i*batch_size\n",
    "#         if num_to_take == 0: break\n",
    "\n",
    "            \n",
    "#         labels_out, images_out = sess.run([labels,images])\n",
    "#         nplabels = np.append(nplabels, labels_out[:num_to_take], axis=0)\n",
    "#         npimages = np.append(npimages, images_out[:num_to_take], axis=0)\n",
    "        \n",
    "#     np.save(features_directory + 'labels', nplabels)\n",
    "#     np.save(features_directory + 'images', npimages)\n",
    "    \n",
    "#     num_runs_eval = (num_eval // batch_size) + 1\n",
    "#     for i in range(num_runs_eval):\n",
    "#         if (i+1) % 5 == 0: print(\"Step {} from {}\".format(i+1, num_runs_eval))\n",
    "#         num_to_take = batch_size\n",
    "#         if i+1 == num_runs_eval: num_to_take = num_eval - i*batch_size\n",
    "#         if num_to_take == 0: break\n",
    "            \n",
    "#         vlabels_out, vimages_out = sess.run([eval_labels,eval_images])\n",
    "#         npvlabels = np.append(npvlabels, vlabels_out[:num_to_take], axis=0)\n",
    "#         npvimages = np.append(npvimages, vimages_out[:num_to_take], axis=0)\n",
    "        \n",
    "#     np.save(features_directory + 'eval_labels', npvlabels)\n",
    "#     np.save(features_directory + 'eval_images', npvimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /local/home/andy/.virtualenvs/main/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v2.py:224: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from ../checkpts/threesplit_resnet_hingeloss_alpha1/checkpoint-20000\n",
      "Values were restored\n",
      "Step 5 from 501\n",
      "Step 10 from 501\n",
      "Step 15 from 501\n",
      "Step 20 from 501\n",
      "Step 25 from 501\n",
      "Step 30 from 501\n",
      "Step 35 from 501\n",
      "Step 40 from 501\n",
      "Step 45 from 501\n",
      "Step 50 from 501\n",
      "Step 55 from 501\n",
      "Step 60 from 501\n",
      "Step 65 from 501\n",
      "Step 70 from 501\n",
      "Step 75 from 501\n",
      "Step 80 from 501\n",
      "Step 85 from 501\n",
      "Step 90 from 501\n",
      "Step 95 from 501\n",
      "Step 100 from 501\n",
      "Step 105 from 501\n",
      "Step 110 from 501\n",
      "Step 115 from 501\n",
      "Step 120 from 501\n",
      "Step 125 from 501\n",
      "Step 130 from 501\n",
      "Step 135 from 501\n",
      "Step 140 from 501\n",
      "Step 145 from 501\n",
      "Step 150 from 501\n",
      "Step 155 from 501\n",
      "Step 160 from 501\n",
      "Step 165 from 501\n",
      "Step 170 from 501\n",
      "Step 175 from 501\n",
      "Step 180 from 501\n",
      "Step 185 from 501\n",
      "Step 190 from 501\n",
      "Step 195 from 501\n",
      "Step 200 from 501\n",
      "Step 205 from 501\n",
      "Step 210 from 501\n",
      "Step 215 from 501\n",
      "Step 220 from 501\n",
      "Step 225 from 501\n",
      "Step 230 from 501\n",
      "Step 235 from 501\n",
      "Step 240 from 501\n",
      "Step 245 from 501\n",
      "Step 250 from 501\n",
      "Step 255 from 501\n",
      "Step 260 from 501\n",
      "Step 265 from 501\n",
      "Step 270 from 501\n",
      "Step 275 from 501\n",
      "Step 280 from 501\n",
      "Step 285 from 501\n",
      "Step 290 from 501\n",
      "Step 295 from 501\n",
      "Step 300 from 501\n",
      "Step 305 from 501\n",
      "Step 310 from 501\n",
      "Step 315 from 501\n",
      "Step 320 from 501\n",
      "Step 325 from 501\n",
      "Step 330 from 501\n",
      "Step 335 from 501\n",
      "Step 340 from 501\n",
      "Step 345 from 501\n",
      "Step 350 from 501\n",
      "Step 355 from 501\n",
      "Step 360 from 501\n",
      "Step 365 from 501\n",
      "Step 370 from 501\n",
      "Step 375 from 501\n",
      "Step 380 from 501\n",
      "Step 385 from 501\n",
      "Step 390 from 501\n",
      "Step 395 from 501\n",
      "Step 400 from 501\n",
      "Step 405 from 501\n",
      "Step 410 from 501\n",
      "Step 415 from 501\n",
      "Step 420 from 501\n",
      "Step 425 from 501\n",
      "Step 430 from 501\n",
      "Step 435 from 501\n",
      "Step 440 from 501\n",
      "Step 445 from 501\n",
      "Step 450 from 501\n",
      "Step 455 from 501\n",
      "Step 460 from 501\n",
      "Step 465 from 501\n",
      "Step 470 from 501\n",
      "Step 475 from 501\n",
      "Step 480 from 501\n",
      "Step 485 from 501\n",
      "Step 490 from 501\n",
      "Step 495 from 501\n",
      "Step 500 from 501\n",
      "Validation. Step 1 from 12\n",
      "Validation. Step 2 from 12\n",
      "Validation. Step 3 from 12\n",
      "Validation. Step 4 from 12\n",
      "Validation. Step 5 from 12\n",
      "Validation. Step 6 from 12\n",
      "Validation. Step 7 from 12\n",
      "Validation. Step 8 from 12\n",
      "Validation. Step 9 from 12\n",
      "Validation. Step 10 from 12\n",
      "Validation. Step 11 from 12\n",
      "Validation. Step 12 from 12\n"
     ]
    }
   ],
   "source": [
    "image_placeholder = tf.placeholder(dtype=tf.uint8, shape=[None, 224*224])\n",
    "for model in models:\n",
    "\n",
    "    model_fn = model['model_fn']\n",
    "    logits   = model_fn(image_placeholder, mode=None, name=model['scope_to_restore'])\n",
    "    var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=model['scope_to_restore'])\n",
    "    \n",
    "    assert len(var_list) > 0\n",
    "    saver = tf.train.Saver(var_list=var_list)\n",
    "    \n",
    "    # Check validity of restoring\n",
    "    with tf.Session() as sess: \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "\n",
    "        checkpoint_dir = checkpoints_directory + model['model_name'] + '/'\n",
    "        # Recover previous work\n",
    "        if 'checkpoint' in model:\n",
    "            ckpt_path = os.path.dirname(checkpoint_dir + 'checkpoint') + '/checkpoint-' + str(model['checkpoint'])\n",
    "        else: \n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname(checkpoint_dir + 'checkpoint'))\n",
    "            if not ckpt: raise Exception(\"No values were restored from model {}\".format(checkpoint_dir))\n",
    "            ckpt_path = ckpt.model_checkpoint_path\n",
    "            \n",
    "        if ckpt_path:\n",
    "            saver.restore(sess, ckpt_path)\n",
    "            print(\"Values were restored\")\n",
    "        else: \n",
    "            raise Exception(\"No values were restored from model {}\".format(checkpoint_dir))\n",
    "            \n",
    "            \n",
    "        ## Save training logits  \n",
    "        assert len(npimages) == num_samples\n",
    "        npfeats  = np.zeros((0,64),      dtype=np.float32)\n",
    "        num_runs = (num_samples // batch_size) + 1\n",
    "        for i in range(num_runs):\n",
    "            if (i+1) % 5 == 0: print(\"Step {} from {}\".format(i+1, num_runs))\n",
    "            num_to_take = batch_size\n",
    "            if i+1 == num_runs: num_to_take = num_samples - i*batch_size\n",
    "            \n",
    "            start_index = i*batch_size\n",
    "            end_index   = start_index + num_to_take\n",
    "            \n",
    "            logits_out = sess.run(logits, feed_dict={image_placeholder: npimages[start_index:end_index]})\n",
    "            if len(logits_out): npfeats = np.append(npfeats, logits_out, axis=0)\n",
    "\n",
    "        np.save(features_directory + 'features_' + model['name_out'], npfeats)\n",
    "\n",
    "        ## Save validation logits\n",
    "        assert len(npvimages) == num_eval\n",
    "        npfeats_eval  = np.zeros((0,64),      dtype=np.float32)\n",
    "        num_runs_eval = (num_eval // batch_size) + 1\n",
    "        for i in range(num_runs_eval):\n",
    "            print(\"Validation. Step {} from {}\".format(i+1, num_runs_eval))\n",
    "            num_to_take = batch_size\n",
    "            if i+1 == num_runs_eval: num_to_take = num_eval - i*batch_size\n",
    "\n",
    "            start_index = i*batch_size\n",
    "            end_index   = start_index + num_to_take\n",
    "            \n",
    "            logits_out = sess.run(logits, feed_dict={image_placeholder: npvimages[start_index:end_index]})\n",
    "            if len(logits_out): npfeats_eval = np.append(npfeats_eval, logits_out, axis=0)\n",
    "\n",
    "        np.save(features_directory + 'eval_features_' + model['name_out'], npfeats_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
